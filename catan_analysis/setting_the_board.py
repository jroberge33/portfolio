# -*- coding: utf-8 -*-
"""Setting the Board

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J1R8UGnCK1vuWh504e7VeDhT1sJyxCHb

# Setting the Board: Studying Catan Strategy with Machine Learning and Data Analysis

## Background
  
A complex analysis of the board game Catan's gameplay, strategy, probabilities, and outcomes would present a very interesting data science and analytics problem. First, with 50 games of online Catan to analyze and Catan being a hugely complex game to play and quantify, this data will not be easily manipulated and analyzed. Catan is enormously difficult to set up, involving 19 unique tiles with 19! ways to arrange said tiles. There are millions of outcomes, each with their own distinct probabilities, and trying to effectively analyze this will be a huge challenge that will also yield incredibly interesting conclusions on probability, game theory and board game strategy. Furthermore, ideally, upon enough analysis, we could apply machine learning techniques to produce outcome probabilities and recommend game strategies to players involved.  

We aim to leverage data visualization and analysis to gain insight into the dynamics of Catan and provide valuable insight for both seasoned players and newcomers. Understanding the correlations between player strategy, luck-driven elements such as dice rolls, and ultimate game results can enhance playersâ€™ strategic thinking and improve their enjoyment of the game. Additionally, it can serve as an educational resource for those interested in the analysis of board games as it applies to probability, game theory, and social interactions.
This project will address the lack of comprehensive data-driven insights of gameplay. While Catan is a renowned board game, there is limited evidence on how strategy and luck impact game outcomes. We plan to collect and clean a dataset containing statistics from 50 games of online Catan. Using this cleaned data, we will conduct exploratory data analysis and visualization to identify patterns relating to starting game placement, the distribution of dice rolls, and resource allocation.

If time allows, we would like to incorporate statistical analysis and machine learning techniques to gain deeper insights and make predictions about future games based on starting positions. We will use regression analysis and hypothesis testing to quantify the impact of our results, as well as predictive modeling and clustering to estimate game outcomes based on distinct playing strategies.

## Data Source
*My Settlers of Catan Games*

https://www.kaggle.com/datasets/lumins/settlers-of-catan-games

# Importing Libraries and Cleaning Data

The following code handles common library imports as well as general data cleaning. We rename the headers of the columns indicating starting positions, as the current names are either empty or unintuitive.
"""

# import libraries and dataset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix
import seaborn as sns
from imblearn.over_sampling import SMOTE
import statsmodels.api as sma
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import statsmodels.api as sm
from statsmodels.formula.api import ols

from google.colab import drive
drive.mount('/content/drive')

RANDOM_STATE = 0

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/catanstats.csv")

# rename untitled settlement columns
df = df.rename(columns={'settlement1': 'settlement1NumA',
                   'Unnamed: 16': 'settlement1ResA',
                   'Unnamed: 17': 'settlement1NumB',
                   'Unnamed: 18': 'settlement1ResB',
                   'Unnamed: 19': 'settlement1NumC',
                   'Unnamed: 20': 'settlement1ResC',
                   'Unnamed: 21': 'settlement2NumA',
                   'Unnamed: 22': 'settlement2ResA',
                   'Unnamed: 23': 'settlement2NumB',
                   'Unnamed: 24': 'settlement2ResB',
                   'Unnamed: 25': 'settlement2NumC',
                   'Unnamed: 26': 'settlement2ResC'})
df.head()

"""# Initial Glimpse: What are common Catan trends?

## Dice Rolls
Catan's core mechanic relies on the roll of two six-sided dice, which determine resource production for players. By analyzing the occurrences of each dice number, we gain a deeper understanding of the game's probability distribution, allowing us to assess the fairness and balance of the game's design.
"""

# drop all columns except dice rolls
diceRolls = df[df['player'] == 1].filter(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])

# add dice rolls from all 50 games
rollSums = diceRolls.sum()

# plot distribution of rolls
rollSums.plot(kind="bar", title="Dice Rolls Over 50 Games",
              xlabel = "Dice Roll", ylabel = "Total Occurrences",
              color = "pink")

"""## Starting Placements

Examining trends in starting placements, both in terms of the number of settlements and resource allocation, is vital in Catan analysis. Players begin collecting resources dependent on their starting placements; preferred spots are oftentimes on numbers that roll more often. Starting placements impact early-game strategy, resource scarcity, and geographic advantages, as different resources are needed to pursue different game strategies. We will first analyze what resource is most commonly settled upon between lumber, clay, wheat, ore, and sheep across all players, and then refine our visualization to winning players.

### Resource Distribution
"""

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# sum all resources for nonwinning players
nonWinningPlayers = df[df['points'] < 10]
nonWinningResources = nonWinningPlayers.filter(['settlement1ResA', 'settlement1ResB',
                                'settlement1ResC', 'settlement2ResA',
                                'settlement2ResB', 'settlement2ResC'])
nonWinningResSums = nonWinningResources.stack().value_counts()
nonWinningResData = nonWinningResSums[nonWinningResSums.index.isin(['S', 'W', 'L', 'O', 'C'])].sort_index()

# plot resources of all players
resourcePlot = nonWinningResData.plot(kind="bar", color="paleturquoise",
                                 title="Among Non-Winning Players",
                                 ax=axes[0])
resourcePlot.set_xticklabels(labels=['Clay', 'Lumber', 'Ore', 'Sheep', 'Wheat'])


# repeat for winning players only
winningPlayers = df[df['points'] >= 10]
winningResources = winningPlayers.filter(['settlement1ResA', 'settlement1ResB',
                                'settlement1ResC', 'settlement2ResA',
                                'settlement2ResB', 'settlement2ResC'])
winningResSums = winningResources.stack().value_counts()
winningResData = winningResSums[winningResSums.index.isin(['S', 'W', 'L', 'O', 'C'])].sort_index()

winningResourcePlot = winningResData.plot(kind="bar", color="paleturquoise",
                                 title="Among Winning Players",
                                 ax=axes[1])
winningResourcePlot.set_xticklabels(labels=['Clay', 'Lumber', 'Ore', 'Sheep', 'Wheat'])

# display plot
fig.suptitle("Frequency of Starting Resources", fontsize=16)
plt.tight_layout()
plt.show()

"""### Number Distribution"""

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# sum all number placements for non-winning players
nonWinningNums = nonWinningPlayers.filter(['settlement1NumA', 'settlement1NumB',
                                'settlement1NumC', 'settlement2NumA',
                                'settlement2NumB', 'settlement2NumC'])
nonWinningNumSums = nonWinningNums.stack().value_counts()
nonWinningNumSums = nonWinningNumSums.sort_index()

# plot number placements
nonWinningNumPlot = nonWinningNumSums.plot(kind="bar", color="orange",
                                 title="Among Non-Winning Players",
                                 ax=axes[0])

# repeat for winning players only
winningNums = winningPlayers.filter(['settlement1NumA', 'settlement1NumB',
                                'settlement1NumC', 'settlement2NumA',
                                'settlement2NumB', 'settlement2NumC'])
winningNumSums = winningNums.stack().value_counts()
winningNumSums = winningNumSums.sort_index()

winningNumPlot = winningNumSums.plot(kind="bar", color="orange",
                                 title="Among Winning Players",
                                 ax=axes[1])

# display plot
fig.suptitle("Frequency of Starting Number Placements", fontsize=16)
plt.tight_layout()
plt.show()

"""Resource Production"""

# calculate average gain by categoryfor nonwinning players
nonWinningProduction = nonWinningPlayers['production'].mean()
nonWinningTradeGain = nonWinningPlayers['tradeGain'].mean()
nonWinningRobberGain = nonWinningPlayers['robberCardsGain'].mean()

nonWinningGainData = {'production': [nonWinningProduction],
                  'tradeGain': [nonWinningTradeGain],
                  'robbberCardsGain': [nonWinningRobberGain],}

nonWinningGainAvgs = pd.DataFrame(data = nonWinningGainData)

# calculate average gain by categoryfor winning players
winningProduction = winningPlayers['production'].mean()
winningTradeGain = winningPlayers['tradeGain'].mean()
winningRobberGain = winningPlayers['robberCardsGain'].mean()

winningGainData = {'production': [winningProduction],
                  'tradeGain': [winningTradeGain],
                  'robbberCardsGain': [winningRobberGain],}

winningGainAvgs = pd.DataFrame(data = winningGainData)

# plot both dataframes on the same bar graph
categories = winningGainAvgs.columns
x = np.arange(len(categories))

plt.figure(figsize=(8, 6))

plt.bar(x - 0.15, nonWinningGainAvgs.values[0], 0.3, color='lightskyblue', label='Non-Winning Players')
plt.bar(x + 0.15, winningGainAvgs.values[0], 0.3, color='palegreen', label='Winning Players')

# add labels
plt.xticks(x, ['Dice Rolls', 'Trading', 'Robber Steals'])
plt.xlabel('Source of Resource Gain')
plt.ylabel('Average Value')
plt.title('Resource Gain for Winning versus Non-Winning Players')
plt.legend()
plt.show()

"""### Card Loss"""

# calculate average gain and loss for nonwinning players
nonWinningTradeLoss = nonWinningPlayers['tradeLoss'].mean()
nonWinningAvgLoss = nonWinningPlayers['robberCardsLoss'].mean()

nonWinningLossData = {'tradeLoss': [nonWinningTradeLoss],
                  'robberCardsLoss': [nonWinningAvgLoss]}

nonWinningLossAvg = pd.DataFrame(data = nonWinningLossData)

# calculate average gain and loss for winning players
winningTradeLoss = winningPlayers['tradeLoss'].mean()
winningAvgLoss = winningPlayers['robberCardsLoss'].mean()

winningLossData = {'tradeLoss': [winningTradeLoss],
                  'robberCardsLoss': [winningAvgLoss]}

winningLossAvg = pd.DataFrame(data = winningLossData)

# plot both dataframes on the same bar graph
categories = winningLossAvg.columns
x = np.arange(len(categories))

plt.figure(figsize=(8, 6))

plt.bar(x - 0.15, nonWinningLossAvg.values[0], 0.3, color='lightskyblue', label='Non-Winning Players')
plt.bar(x + 0.15, winningLossAvg.values[0], 0.3, color='palegreen', label='Winning Players')

# add labels
plt.xticks(x, ['Trade Loss', 'Robber Loss'])
plt.xlabel('Source of Resource Loss')
plt.ylabel('Average Value')
plt.title('Resource Loss for Winning versus Non-Winning Players')
plt.legend()
plt.show()

"""### Gain versus Loss"""

# calculate average gain and loss for nonwinning players
nonWinningAvgGain = nonWinningPlayers['totalGain'].mean()
nonWinningAvgLoss = nonWinningPlayers['totalLoss'].mean()

nonWinningData = {'averageGain': [nonWinningAvgGain],
                  'averageLoss': [nonWinningAvgLoss]}

nonWinningGainLossAvg = pd.DataFrame(data = nonWinningData)

# calculate average gain and loss for winning players
winningAvgGain = winningPlayers['totalGain'].mean()
winningAvgLoss = winningPlayers['totalLoss'].mean()

winningData = {'averageGain': [winningAvgGain],
                  'averageLoss': [winningAvgLoss]}

winningGainLossAvg = pd.DataFrame(data = winningData)

# plot both dataframes on the same bar graph
categories = winningGainLossAvg.columns
x = np.arange(len(categories))

plt.figure(figsize=(8, 6))

plt.bar(x - 0.15, nonWinningGainLossAvg.values[0], 0.3, color='mediumpurple', label='Non-Winning Players')
plt.bar(x + 0.15, winningGainLossAvg.values[0], 0.3, color='lightpink', label='Winning Players')

# add labels
plt.xticks(x, ['Cards Gained', 'Cards Lost'])
plt.xlabel('Category')
plt.ylabel('Average Value')
plt.title('Card Gain and Loss for Winning Versus Non-Winning Players')
plt.legend()
plt.show()

"""## Other Factors

### How quickly do games end?

"""

# sum the amount of rounds for every game
diceRolls['TotalRolls'] = diceRolls.sum(axis=1)
diceRolls['TotalRounds'] = round(diceRolls['TotalRolls'] / 4)

# plot
rounds = diceRolls['TotalRounds'].value_counts()
plt.bar(rounds.index, rounds.values, color='pink')
plt.title('Frequency of Rounds in Games')
plt.xlabel('Rounds in One Game')
plt.ylabel('Frequency')
plt.show()

"""# Machine Learning

## How Starting Position Affects Outcome

Examining the starting placements of players, we will look at how both number and resource starting placements impacts the players' performance through the game, essentially trying to determine how much of an impact a player's starting placements have on their success in the game.

### KNN Algorithm

KNN CLASSIFIER WITH ONLY STARTING RESOURCES, NOT USING SMOTE OVERSAMPLING
"""

# add a column to the dataframe detailing the winner of each game
games = set(df['gameNum'])
wins = []
for i in range(len(df['player'])):
  if int(df.iloc[i]['points']) >= 10:
    wins.append(1)
  else:
    wins.append(0)
df['win'] = wins

# define win/loss outcome as labels
dataLabels = df['win']

# count each resource for each player's initial placements and make this a dataframe
resources = df.filter(['settlement1ResA', 'settlement1ResB',
                                'settlement1ResC', 'settlement2ResA',
                                'settlement2ResB', 'settlement2ResC'])
resourceSums = resources.stack().value_counts()
unique_resources = list(resourceSums.keys())
playerStartingResources = df[['settlement1ResA', 'settlement1ResB',
                                'settlement1ResC', 'settlement2ResA',
                                'settlement2ResB', 'settlement2ResC']]
i = 0
j = 0
resource_counts = []
while i < len(playerStartingResources):
  player_resources = playerStartingResources.stack().iloc[j:j+6]
  resource_counts.append(player_resources.value_counts())
  i += 1
  j += 6
resource_count_dct = {}
for resource in unique_resources:
  resource_count_dct[resource] = []
for i in range(len(resource_counts)):
  for resource in unique_resources:
    resources_placed = list(resource_counts[i].keys())
    if resource in resources_placed:
      resource_count_dct[resource].append(resource_counts[i][resources_placed.index(resource)])
    else:
      resource_count_dct[resource].append(0)

resource_placement_df = pd.DataFrame(resource_count_dct)

# group data into testing data and training data
features_train, features_test, labels_train, labels_test = train_test_split(resource_placement_df, dataLabels, test_size = 0.25, random_state = RANDOM_STATE)

# create an instance of our knn model with k = 3, to be optimized later
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(features_train, labels_train)
label_prediction = knn.predict(features_test)
accuracy = accuracy_score(labels_test, label_prediction)
print(f"The accuracy of our model is currently: {accuracy}")


# we can now use cross validation to optimize the accuracy of our model
k_values = [i for i in range(1,31)]
scores = []
for k in k_values:
  knn = KNeighborsClassifier(n_neighbors = k)
  score = cross_val_score(knn, resource_placement_df, dataLabels, cv = 5)
  scores.append(np.mean(score))

sns.lineplot(x = k_values, y = scores)
plt.title("K Values vs Accuracy Score")
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

optimal_k_value = scores.index(max(scores)) + 1
print(f"Thus, the optimal value of k for our model is: {optimal_k_value}, associated with the accuracy score of: {max(scores)}")

# with our optimized k, we can now retrain our model and evaluate its performance

knn = KNeighborsClassifier(n_neighbors = optimal_k_value)
knn.fit(features_train, labels_train)

labels_prediction = knn.predict(features_test)

accuracy = accuracy_score(labels_test, labels_prediction)
precision = precision_score(labels_test, labels_prediction)
recall = recall_score(labels_test, labels_prediction)

print(classification_report(labels_test, labels_prediction))

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

cnf_matrix = metrics.confusion_matrix(labels_test, labels_prediction)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix for KNN Classification', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# UH-OH!

"""KNN CLASSIFIER WITH ONLY STARTING RESOURCES, USING SMOTE OVERSAMPLING

---


"""

# group data into testing data and training data
features_train, features_test, labels_train, labels_test = train_test_split(resource_placement_df, dataLabels, test_size = 0.25, random_state = RANDOM_STATE)

# oversample the training data to account for underrepresentation of wins in data set
sm = SMOTE(random_state = RANDOM_STATE)
features_train_resampled, labels_train_resampled = sm.fit_resample(features_train, labels_train)
data_columns = features_train.columns

# showcasing resampling of training data
features_train_resampled = pd.DataFrame(data = features_train_resampled, columns = data_columns)
labels_train_resampled = pd.DataFrame(data = labels_train_resampled, columns=['win'])

# display key sampling information for the oversampled data
print("The length of oversampled data is: ",len(features_train_resampled))
print("The number of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0]))
print("Number of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1]))
print("Proportion of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0])/len(features_train_resampled))
print("Proportion of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1])/len(features_train_resampled))

# create an instance of our knn model with k = 3, to be optimized later
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(features_train_resampled, labels_train_resampled)
label_prediction = knn.predict(features_test)
accuracy = accuracy_score(labels_test, label_prediction)
print(f"The accuracy of our model is currently: {accuracy}")

# we can now use cross validation to optimize the accuracy of our model
k_values = [i for i in range(1,31)]
scores = []
for k in k_values:
  knn = KNeighborsClassifier(n_neighbors = k)
  score = cross_val_score(knn, features_train_resampled, labels_train_resampled, cv = 5)
  scores.append(np.mean(score))

sns.lineplot(x = k_values, y = scores)
plt.title("K Values vs Accuracy Score")
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

optimal_k_value = scores.index(max(scores)) + 1
print(f"Thus, the optimal value of k for our model is: {optimal_k_value}, associated with the accuracy score of: {max(scores)}")

# with our optimized k, we can now retrain our model and evaluate its performance

knn = KNeighborsClassifier(n_neighbors = optimal_k_value)
knn.fit(features_train_resampled, labels_train_resampled)

labels_prediction = knn.predict(features_test)

accuracy = accuracy_score(labels_test, labels_prediction)
precision = precision_score(labels_test, labels_prediction)
recall = recall_score(labels_test, labels_prediction)

print(classification_report(labels_test, labels_prediction))

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

cnf_matrix = metrics.confusion_matrix(labels_test, labels_prediction)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix for KNN Classification', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

"""KNN CLASSIFIER AND LOGISTIC REGRESSION WITH STARTING RESOURCES AND NUMBERS, USING SMOTE OVERSAMPLING"""

# count each number for each player's initial placements and make this a dataframe
numbers = df.filter(['settlement1NumA', 'settlement1NumB',
                                'settlement1NumC', 'settlement2',
                                'settlement2NumB', 'settlement2NumC'])
numbers = numbers.stack().value_counts()
unique_numbers = list(numbers.keys())

playerStartingNumbers = df[['settlement1NumA', 'settlement1NumB',
                                'settlement1NumC', 'settlement2',
                                'settlement2NumB', 'settlement2NumC']]
i = 0
j = 0
starting_count_dct = resource_count_dct
number_counts = []
while i < len(playerStartingNumbers):
  player_numbers = playerStartingNumbers.stack().iloc[j:j+6]
  number_counts.append(player_numbers.value_counts())
  i += 1
  j += 6
for number in unique_numbers:
  starting_count_dct[number] = []
for i in range(len(number_counts)):
  for number in unique_numbers:
    numbers_placed = list(number_counts[i].keys())
    if number in numbers_placed:
      starting_count_dct[number].append(number_counts[i][number])
    else:
      starting_count_dct[number].append(0)

starting_placement_df = pd.DataFrame(starting_count_dct)
#starting_placement_df.drop(columns = ['0', '2', '3', '4', '5', '6', '8', '9', '10', '11', '12'], inplace = True)
starting_placement_df.columns = starting_placement_df.columns.astype(str)

# group data into testing data and training data
features_train, features_test, labels_train, labels_test = train_test_split(starting_placement_df, dataLabels, test_size = 0.25, random_state = RANDOM_STATE)

# oversample the training data to account for underrepresentation of wins in data set
sm = SMOTE(random_state = RANDOM_STATE)
features_train_resampled, labels_train_resampled = sm.fit_resample(features_train, labels_train)
data_columns = features_train.columns

# showcasing resampling of training data
features_train_resampled = pd.DataFrame(data = features_train_resampled, columns = data_columns)
labels_train_resampled = pd.DataFrame(data = labels_train_resampled, columns=['win'])

# display key sampling information for the oversampled data
print("The length of oversampled data is: ",len(features_train_resampled))
print("The number of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0]))
print("Number of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1]))
print("Proportion of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0])/len(features_train_resampled))
print("Proportion of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1])/len(features_train_resampled))

# create an instance of our knn model with k = 3, to be optimized later
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(features_train_resampled, labels_train_resampled)
label_prediction = knn.predict(features_test)
accuracy = accuracy_score(labels_test, label_prediction)
print(f"The accuracy of our model is currently: {accuracy}")

# we can now use cross validation to optimize the accuracy of our model
k_values = [i for i in range(1,31)]
scores = []
for k in k_values:
  knn = KNeighborsClassifier(n_neighbors = k)
  score = cross_val_score(knn, starting_placement_df, dataLabels, cv = 5)
  scores.append(np.mean(score))

sns.lineplot(x = k_values, y = scores)
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

optimal_k_value = scores.index(max(scores)) + 1
print(f"Thus, the optimal value of k for our model is: {optimal_k_value}, associated with the accuracy score of: {max(scores)}")

# with our optimized k, we can now retrain our model and evaluate its performance

knn = KNeighborsClassifier(n_neighbors = optimal_k_value)
knn.fit(features_train_resampled, labels_train_resampled)

labels_prediction = knn.predict(features_test)

accuracy = accuracy_score(labels_test, labels_prediction)
precision = precision_score(labels_test, labels_prediction)
recall = recall_score(labels_test, labels_prediction)

print(classification_report(labels_test, labels_prediction))

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

cnf_matrix = metrics.confusion_matrix(labels_test, labels_prediction)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix for KNN Classification', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

sc = StandardScaler()
features_train_resampled = sc.fit_transform(features_train_resampled)
features_test = sc.fit_transform(features_test)

logreg = LogisticRegression(random_state = RANDOM_STATE)

logreg.fit(features_train_resampled, labels_train_resampled)
labels_prediction = logreg.predict(features_test)

cnf_matrix = metrics.confusion_matrix(labels_test, labels_prediction)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix for Logistic Regression', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print(classification_report(labels_test, labels_prediction))

"""LOGISTIC REGRESSION USING STARTING PLACEMENT RESOURCE AND NUMBER COMBINATIONS (PCA ANALYSIS)"""

# create new columns indicating the combination of a specific starting resource and number
df['settlement1A'] = df['settlement1ResA'] + df['settlement1NumA'].astype(str)
df['settlement1B'] = df['settlement1ResB'] + df['settlement1NumB'].astype(str)
df['settlement1C'] = df['settlement1ResC'] + df['settlement1NumC'].astype(str)
df['settlement2A'] = df['settlement2ResA'] + df['settlement2'].astype(str)
df['settlement2B'] = df['settlement2ResB'] + df['settlement2NumB'].astype(str)
df['settlement2C'] = df['settlement2ResC'] + df['settlement2NumC'].astype(str)

# create dummy columns indicating a boolean '1' or '0' for every possible combination of starting resource and number
dummies_df = pd.get_dummies(df, columns = ['settlement1A', 'settlement1B', 'settlement1C', 'settlement2A', 'settlement2B', 'settlement2C'])

starting_combination_columns = dummies_df.iloc[:, 37:]
results = dummies_df.iloc[:, 36]

# group data into testing data and training data
features_train, features_test, labels_train, labels_test = train_test_split(starting_combination_columns, results, test_size = 0.25, random_state = RANDOM_STATE)

# oversample the training data to account for underrepresentation of wins in data set
sm = SMOTE(random_state = RANDOM_STATE)
features_train_resampled, labels_train_resampled = sm.fit_resample(features_train, labels_train)
data_columns = features_train.columns

# showcasing resampling of training data
features_train_resampled = pd.DataFrame(data = features_train_resampled, columns = data_columns)
labels_train_resampled = pd.DataFrame(data = labels_train_resampled, columns=['win'])

# display key sampling information for the oversampled data
print("The length of oversampled data is: ",len(features_train_resampled))
print("The number of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0]))
print("Number of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1]))
print("Proportion of losses in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==0])/len(features_train_resampled))
print("Proportion of wins in oversampled data is: ",len(labels_train_resampled[labels_train_resampled['win']==1])/len(features_train_resampled))

# create a logistic regression model to analyze which combinations have an outsized impact on results

pca = PCA(n_components = 20)
principalComponents_train = pca.fit_transform(features_train_resampled)
principalComponents_test = pca.fit_transform(features_test)
principalDf = pd.DataFrame(data = principalComponents_train)

sc = StandardScaler()
principalComponents_train = sc.fit_transform(principalComponents_train)
principalComponents_test = sc.fit_transform(principalComponents_test)

logreg = LogisticRegression(random_state = RANDOM_STATE)

logreg.fit(principalComponents_train, labels_train_resampled)
labels_prediction = logreg.predict(principalComponents_test)

cnf_matrix = metrics.confusion_matrix(labels_test, labels_prediction)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix for Logistic Regression', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print(classification_report(labels_test, labels_prediction))

accuracy = accuracy_score(labels_test, labels_prediction)
precision = precision_score(labels_test, labels_prediction)
recall = recall_score(labels_test, labels_prediction)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")